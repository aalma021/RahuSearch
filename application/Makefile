PROJECT := rahusearch
COMPOSE := docker-compose.yml
PINGGY_PORT := 3000
API_HEALTH_URL := http://localhost:8000/health

.PHONY: up all stop restart predeploy predeploy-build vllm-up vllm-stop add_data


# -------------------------
# SAFE DEMO FLOW
# stop -> up -> wait api -> pinggy
# -------------------------
all:
	@echo "üßπ Stopping existing containers..."
	docker compose -p $(PROJECT) -f $(COMPOSE) down

	@echo "üõë Stopping vLLM if running..."
	@docker stop rahusearch-vllm || true

	@echo "üöÄ Starting runtime services..."
	docker compose -p $(PROJECT) -f $(COMPOSE) up -d --build weaviate api frontend

	@if [ "$(EMBED_RUNTIME)" = "local" ]; then \
		echo "üü¢ EMBEDDING MODE: LOCAL (vLLM will be started)"; \
		$(MAKE) vllm-up; \
	else \
		echo "üîµ EMBEDDING MODE: EXTERNAL (vLLM will NOT be started)"; \
	fi

	@echo "‚è≥ Waiting for Weaviate..."
	@bash -c '\
	for i in {1..120}; do \
		if curl -s http://localhost:8080/v1/meta >/dev/null; then \
			echo "‚úÖ Weaviate ready"; exit 0; \
		fi; \
		sleep 1; \
	done; \
	echo "‚ùå Weaviate timeout"; exit 1;'

	@echo "‚è≥ Waiting for API..."
	@bash -c '\
	for i in {1..120}; do \
		if curl -s -o /dev/null -w "%{http_code}" $(API_HEALTH_URL) | grep -q 200; then \
			echo "‚úÖ API ready"; exit 0; \
		fi; \
		sleep 1; \
	done; \
	echo "‚ùå API timeout"; exit 1;'

	@echo "üåç Opening Pinggy tunnel..."
	ssh -p 443 -R 80:localhost:$(PINGGY_PORT) a.pinggy.io


# -------------------------
# vLLM EMBEDDING SERVER
# -------------------------
vllm-up:
	@echo "üöÄ Starting vLLM embedding server (CPU)..."
	@docker run -d --rm \
		--name rahusearch-vllm \
		--env-file .env \
		-p $(EMBED_PORT):8000 \
		vllm/vllm-openai:cpu \
		serve $$VLLM_MODEL \
		--runner $$VLLM_RUNNER \
		--port 8000 \
		--max-model-len $$VLLM_MAX_MODEL_LEN


vllm-stop:
	@echo "üõë Stopping vLLM embedding server..."
	@docker stop rahusearch-vllm || true


# -------------------------
# FAST DEV FLOW (no down)
# -------------------------
up:
	docker compose -p $(PROJECT) -f $(COMPOSE) up -d --build


predeploy-build:
	@echo "üõ†Ô∏è Building predeploy image..."
	docker build -t rahusearch-predeploy -f pre_deploy/Dockerfile .


predeploy: predeploy-build
	@echo "üì¶ Running predeploy (index + embeddings, one-shot)..."
	docker compose -p $(PROJECT) -f $(COMPOSE) up -d weaviate
	docker compose -p $(PROJECT) -f $(COMPOSE) run --rm predeploy
	docker compose -p $(PROJECT) -f $(COMPOSE) down

add_data:
	@echo "‚ûï Running update service (add / upsert data)..."
	docker compose -p $(PROJECT) -f $(COMPOSE) up -d weaviate
	docker compose -p $(PROJECT) -f $(COMPOSE) run --rm update


stop:
	@docker stop rahusearch-vllm || true
	docker compose -p $(PROJECT) -f $(COMPOSE) down


restart: stop up
